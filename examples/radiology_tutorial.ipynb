{"cells":[{"cell_type":"markdown","metadata":{"id":"qdw_q75-9cuw"},"source":["# HoneyBee Radiology Processing Tutorial\n","\n","This comprehensive tutorial demonstrates the radiology processing capabilities of HoneyBee, including:\n","- Loading DICOM and NIfTI files\n","- Image preprocessing and enhancement\n","- Anatomical segmentation\n","- Spatial standardization\n","- Embedding generation for downstream AI tasks\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"VENJg2eM9cux"},"source":["## Table of Contents\n","1. [Setup and Installation](#setup)\n","2. [Loading Medical Images](#loading)\n","3. [Image Preprocessing](#preprocessing)\n","4. [Window/Level Adjustment](#windowing)\n","5. [Denoising Techniques](#denoising)\n","6. [Anatomical Segmentation](#segmentation)\n","7. [Spatial Standardization](#spatial)\n","8. [Intensity Normalization](#normalization)\n","9. [Embedding Generation](#embeddings)\n","10. [Complete Pipeline Example](#pipeline)\n","11. [Advanced Topics](#advanced)"]},{"cell_type":"markdown","metadata":{"id":"0fjlb1Ze9cuy"},"source":["## 1. Setup and Installation <a id='setup'></a>\n","\n","First, let's import all necessary libraries and set up our environment."]},{"cell_type":"markdown","source":["### a.  Setup Google Drive and Clone HoneyBee Git Repo"],"metadata":{"id":"RsJZJglY-S1C"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hZ94YyBN-aPT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","#### **NOTE:** If you ran the Clinical Processing Tutorial first, you already have the HoneyBee base code in your drive. In that case, just run the following cell once and ignore the error: 'destination path 'HoneyBee' already exists'.\n","\n","\n","---\n","\n"],"metadata":{"id":"hMyoB96k-sI1"}},{"cell_type":"code","source":["%%bash\n","cd /content/drive/MyDrive/\n","mkdir -p HoneyBee_MayoWorkshop\n","cd HoneyBee_MayoWorkshop\n","git clone https://github.com/lab-rasool/HoneyBee-Workshop.git"],"metadata":{"id":"7NlxL9_F-nZD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### b. Install Dependencies"],"metadata":{"id":"DdepY4Xk_PQ6"}},{"cell_type":"code","source":["!apt-get update\n","!apt-get install -y openslide-tools tesseract-ocr"],"metadata":{"id":"q2gwL1H1_Mjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Standard libraries\n","import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings('ignore')\n","sys.path.append('/content/drive/MyDrive/HoneyBee_MayoWorkshop/HoneyBee-Workshop')"],"metadata":{"id":"JngChUXQ_cs0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### c. Install packages, Restart the Session if asked and rerun all previous cells again"],"metadata":{"id":"GMfqjLeTAeqh"}},{"cell_type":"code","source":["!pip install -r /content/drive/MyDrive/HoneyBee_MayoWorkshop/HoneyBee-Workshop/requirements.txt"],"metadata":{"id":"4YGiJIMn_lBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# if any of the below mentioned package installation fails, uncomment the following line to install that package\n","#!pip install SimpleITK\n","#!pip install onnxruntime --upgrade"],"metadata":{"id":"ObIgQpmKA2JA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import HoneyBee components\n","from honeybee.processors import RadiologyProcessor, RadiologyImage\n","\n","# Set up visualization parameters\n","plt.rcParams['figure.figsize'] = (12, 8)\n","plt.rcParams['figure.dpi'] = 100\n","plt.rcParams['font.size'] = 12\n","\n","print(\"HoneyBee Radiology Processing loaded successfully!\")"],"metadata":{"id":"BuWXK_UcA1_t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EToWHLDW9cuz"},"source":["### Initialize the RadiologyProcessor\n","\n","The RadiologyProcessor supports different embedding models:\n","- **REMEDIS**: Medical image embeddings specialized for radiology\n","- **RadImageNet**: Pre-trained models for radiological image analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19SAbm0s9cuz"},"outputs":[],"source":["# Initialize the processor\n","processor = RadiologyProcessor(model=\"remedis\")\n","print(f\"Processor initialized with {processor.model_name} model on {processor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"uKXXd4pL9cuz"},"source":["## 2. Loading Medical Images <a id='loading'></a>\n","\n","HoneyBee supports multiple medical imaging formats:\n","- **DICOM**: The standard format for medical imaging\n","- **NIfTI**: Common in research and neuroimaging\n","- **NRRD/MHD**: Other medical imaging formats"]},{"cell_type":"markdown","metadata":{"id":"d7p38HHr9cu0"},"source":["### Loading DICOM Files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GNFXOr-9cu0"},"outputs":[],"source":["# Path to sample CT DICOM series\n","ct_dir = Path(\"/content/drive/MyDrive/HoneyBee_MayoWorkshop/HoneyBee-Workshop/examples/samples/CT/1.3.6.1.4.1.14519.5.2.1.6450.4007.120939979254568619864019915915/1.3.6.1.4.1.14519.5.2.1.6450.4007.120939979254568619864019915915/\")\n","\n","# Load DICOM series\n","ct_image = processor.load_dicom(ct_dir)\n","\n","print(f\"Loaded CT image:\")\n","print(f\"  Shape: {ct_image.shape}\")\n","print(f\"  Data type: {ct_image.dtype}\")\n","print(f\"  Intensity range: [{ct_image.data.min():.1f}, {ct_image.data.max():.1f}]\")\n","print(f\"\\nMetadata available:\")\n","for key in list(ct_image.metadata.keys())[:8]:\n","    print(f\"  - {key}: {ct_image.metadata[key]}\")"]},{"cell_type":"markdown","metadata":{"id":"0dNnkM6o9cu1"},"source":["### Visualizing the Loaded Image\n","\n","Let's create a helper function to visualize slices from our 3D volume."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJ5WTx3O9cu1"},"outputs":[],"source":["def show_slices(image_data, title=\"Image\", slice_indices=None, cmap='gray'):\n","    \"\"\"Display multiple slices from a 3D volume.\"\"\"\n","    if slice_indices is None:\n","        # Show 6 evenly spaced slices\n","        n_slices = image_data.shape[0]\n","        slice_indices = np.linspace(10, n_slices-10, 6, dtype=int)\n","\n","    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n","    axes = axes.flatten()\n","\n","    for idx, (ax, slice_idx) in enumerate(zip(axes, slice_indices)):\n","        ax.imshow(image_data[slice_idx], cmap=cmap)\n","        ax.set_title(f\"Slice {slice_idx}\")\n","        ax.axis('off')\n","\n","    plt.suptitle(title, fontsize=16)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Show original CT slices\n","show_slices(ct_image.data, \"Original CT Scan\")"]},{"cell_type":"markdown","metadata":{"id":"MyWmI81t9cu2"},"source":["### Interactive Slice Viewer\n","\n","For better exploration, let's create an interactive viewer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-NquqoL9cu2"},"outputs":[],"source":["from ipywidgets import interact, IntSlider\n","\n","def view_slice(slice_idx):\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(ct_image.data[slice_idx], cmap='gray')\n","    plt.colorbar(label='Intensity')\n","    plt.title(f\"CT Slice {slice_idx}/{ct_image.shape[0]-1}\")\n","    plt.axis('off')\n","    plt.show()\n","\n","# Create interactive slider\n","interact(view_slice, slice_idx=IntSlider(min=0, max=ct_image.shape[0]-1, value=20, description='Slice:'))"]},{"cell_type":"markdown","metadata":{"id":"-6HIzAqD9cu2"},"source":["## 3. Image Preprocessing <a id='preprocessing'></a>\n","\n","Preprocessing is crucial for medical image analysis. Let's start with Hounsfield Unit (HU) verification for CT scans."]},{"cell_type":"markdown","metadata":{"id":"ODQOYxv29cu2"},"source":["### Hounsfield Unit Verification\n","\n","CT scanners measure radiodensity in Hounsfield Units (HU):\n","- Air: -1000 HU\n","- Water: 0 HU\n","- Soft tissue: +40 to +80 HU\n","- Bone: +700 to +3000 HU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"21UIgH-59cu2"},"outputs":[],"source":["# Verify and correct Hounsfield units\n","ct_hu = processor.verify_hounsfield_units(ct_image)\n","\n","print(f\"After HU verification:\")\n","print(f\"  HU range: [{ct_hu.data.min():.1f}, {ct_hu.data.max():.1f}]\")\n","\n","# Plot histogram of HU values\n","plt.figure(figsize=(12, 5))\n","hist_data = ct_hu.data.flatten()\n","hist_data = hist_data[hist_data > -1000]  # Remove air background\n","\n","plt.hist(hist_data, bins=100, alpha=0.7, color='blue', edgecolor='black')\n","plt.axvline(x=-1000, color='red', linestyle='--', label='Air (-1000 HU)')\n","plt.axvline(x=0, color='green', linestyle='--', label='Water (0 HU)')\n","plt.axvline(x=50, color='orange', linestyle='--', label='Soft Tissue (~50 HU)')\n","plt.xlabel('Hounsfield Units (HU)')\n","plt.ylabel('Frequency')\n","plt.title('Distribution of Hounsfield Units in CT Scan')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1BF3jXIM9cu2"},"source":["## 4. Window/Level Adjustment <a id='windowing'></a>\n","\n","Different anatomical structures are best visualized with specific window/level settings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ygoVS-B9cu2"},"outputs":[],"source":["# Apply different window presets\n","windows = {\n","    \"Lung\": processor.apply_window(ct_hu, **processor.WINDOW_PRESETS[\"lung\"]),\n","    \"Soft Tissue\": processor.apply_window(ct_hu, **processor.WINDOW_PRESETS[\"soft_tissue\"]),\n","    \"Bone\": processor.apply_window(ct_hu, **processor.WINDOW_PRESETS[\"bone\"]),\n","    \"Brain\": processor.apply_window(ct_hu, **processor.WINDOW_PRESETS[\"brain\"])\n","}\n","\n","# Visualize different windows\n","fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n","axes = axes.flatten()\n","\n","slice_idx = 25  # Use earlier slice for better lung visualization\n","\n","for ax, (name, windowed) in zip(axes, windows.items()):\n","    ax.imshow(windowed.data[slice_idx], cmap='gray')\n","    ax.set_title(f\"{name} Window\", fontsize=14)\n","    ax.axis('off')\n","\n","    # Add window parameters as text\n","    window_info = f\"W: {windowed.metadata['window']}, L: {windowed.metadata['level']}\"\n","    ax.text(0.02, 0.98, window_info, transform=ax.transAxes,\n","            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n","            verticalalignment='top', fontsize=10)\n","\n","plt.suptitle('Different Window/Level Settings for CT Visualization', fontsize=16)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"LF7nUrsV9cu3"},"source":["### Custom Window/Level Settings\n","\n","You can also create custom window/level settings for specific visualization needs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rjc134YJ9cu3"},"outputs":[],"source":["# Interactive window/level adjustment\n","from ipywidgets import interact, FloatSlider\n","\n","def adjust_window(window, level, slice_idx):\n","    windowed = processor.apply_window(ct_hu, window=window, level=level)\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(windowed.data[slice_idx], cmap='gray')\n","    plt.colorbar(label='Normalized Intensity')\n","    plt.title(f\"Window: {window:.0f}, Level: {level:.0f}\")\n","    plt.axis('off')\n","    plt.show()\n","\n","interact(adjust_window,\n","         window=FloatSlider(min=1, max=3000, value=400, description='Window:'),\n","         level=FloatSlider(min=-1000, max=1000, value=50, description='Level:'),\n","         slice_idx=IntSlider(min=0, max=ct_image.shape[0]-1, value=25, description='Slice:'))"]},{"cell_type":"markdown","metadata":{"id":"C-QU6pcK9cu3"},"source":["## 5. Denoising Techniques <a id='denoising'></a>\n","\n","Medical images often contain noise that can affect analysis. HoneyBee provides multiple denoising methods."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rB02Rkef9cu4"},"outputs":[],"source":["# Apply different denoising methods\n","denoising_methods = {\n","    \"Original\": ct_hu,\n","    \"Non-Local Means\": processor.denoise(ct_hu, method=\"nlm\"),\n","    \"Total Variation\": processor.denoise(ct_hu, method=\"tv\"),\n","    \"Bilateral Filter\": processor.denoise(ct_hu, method=\"bilateral\")\n","}\n","\n","# Compare denoising methods\n","fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n","axes = axes.flatten()\n","\n","slice_idx = 25\n","# Use a zoomed region for better comparison\n","zoom_slice = slice(200, 350)\n","\n","for ax, (name, denoised) in zip(axes, denoising_methods.items()):\n","    # Show zoomed region\n","    ax.imshow(denoised.data[slice_idx, zoom_slice, zoom_slice], cmap='gray')\n","    ax.set_title(f\"{name}\", fontsize=14)\n","    ax.axis('off')\n","\n","    # Calculate noise metrics\n","    if name != \"Original\":\n","        diff = np.abs(denoised.data[slice_idx] - ct_hu.data[slice_idx])\n","        noise_reduction = np.mean(diff)\n","        ax.text(0.02, 0.02, f\"Avg diff: {noise_reduction:.2f}\",\n","                transform=ax.transAxes,\n","                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n","                fontsize=10)\n","\n","plt.suptitle('Comparison of Denoising Methods (Zoomed Region)', fontsize=16)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"_B41Bv7V9cu4"},"source":["### Noise Analysis\n","\n","Let's analyze the effectiveness of each denoising method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTeX3rkC9cu4"},"outputs":[],"source":["# Calculate signal-to-noise ratio (SNR) for each method\n","def calculate_snr(image_data, roi_center=(256, 256), roi_size=50):\n","    \"\"\"Calculate SNR in a region of interest.\"\"\"\n","    slice_idx = image_data.shape[0] // 2\n","\n","    # Extract ROI\n","    y, x = roi_center\n","    roi = image_data[slice_idx,\n","                     y-roi_size//2:y+roi_size//2,\n","                     x-roi_size//2:x+roi_size//2]\n","\n","    # Calculate SNR\n","    signal = np.mean(roi)\n","    noise = np.std(roi)\n","    snr = signal / noise if noise > 0 else 0\n","\n","    return snr\n","\n","# Compare SNR for different methods\n","print(\"Signal-to-Noise Ratio Comparison:\")\n","print(\"-\" * 40)\n","for name, denoised in denoising_methods.items():\n","    snr = calculate_snr(denoised.data)\n","    print(f\"{name:<20}: {snr:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"IqjbACl69cu4"},"source":["## 6. Anatomical Segmentation <a id='segmentation'></a>\n","\n","Segmentation is crucial for isolating specific anatomical structures. Let's demonstrate lung segmentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99B0LXhI9cu4"},"outputs":[],"source":["# Perform lung segmentation\n","print(\"Performing lung segmentation...\")\n","lung_mask = processor.segment_lungs(ct_hu)\n","\n","# Apply mask to get segmented lungs\n","masked_lungs = processor.apply_mask(ct_hu, lung_mask)\n","\n","print(f\"Lung mask shape: {lung_mask.shape}\")\n","print(f\"Number of lung voxels: {np.sum(lung_mask):,}\")\n","print(f\"Percentage of volume: {100 * np.sum(lung_mask) / lung_mask.size:.2f}%\")"]},{"cell_type":"markdown","metadata":{"id":"acMDBinF9cu5"},"source":["### Visualize Lung Segmentation\n","\n","Let's visualize the segmentation results across multiple slices, focusing on the upper chest where lungs are most visible."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIQccNkZ9cu5"},"outputs":[],"source":["# Show segmentation results on multiple slices\n","fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n","\n","# Use slices from upper chest area (10-40)\n","slice_indices = [90, 95, 100]\n","\n","for col, slice_idx in enumerate(slice_indices):\n","    # Original CT\n","    axes[0, col].imshow(ct_hu.data[slice_idx], cmap='gray')\n","    axes[0, col].set_title(f\"Original - Slice {slice_idx}\")\n","    axes[0, col].axis('off')\n","\n","    # Lung mask overlay\n","    axes[1, col].imshow(ct_hu.data[slice_idx], cmap='gray', alpha=0.7)\n","    axes[1, col].imshow(lung_mask[slice_idx], cmap='hot', alpha=0.3)\n","    axes[1, col].set_title(f\"Lung Mask Overlay\")\n","    axes[1, col].axis('off')\n","\n","    # Segmented lungs only\n","    axes[2, col].imshow(masked_lungs.data[slice_idx], cmap='gray')\n","    axes[2, col].set_title(f\"Segmented Lungs\")\n","    axes[2, col].axis('off')\n","\n","plt.suptitle('Lung Segmentation Results Across Multiple Slices', fontsize=18)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ht9yGbKY9cu5"},"source":["### 3D Visualization of Lung Segmentation\n","\n","Let's create a 3D visualization to better understand the segmentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6yGTvVfy9cu6"},"outputs":[],"source":["# Create maximum intensity projection (MIP) views\n","fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n","\n","# Axial MIP (top-down view)\n","axial_mip = np.max(masked_lungs.data[10:40], axis=0)\n","axes[0].imshow(axial_mip, cmap='gray')\n","axes[0].set_title('Axial MIP (Top View)', fontsize=14)\n","axes[0].axis('off')\n","\n","# Coronal MIP (front view)\n","coronal_mip = np.max(masked_lungs.data[10:40], axis=1)\n","axes[1].imshow(coronal_mip, cmap='gray', aspect='auto')\n","axes[1].set_title('Coronal MIP (Front View)', fontsize=14)\n","axes[1].axis('off')\n","\n","# Sagittal MIP (side view)\n","sagittal_mip = np.max(masked_lungs.data[10:40], axis=2)\n","axes[2].imshow(sagittal_mip, cmap='gray', aspect='auto')\n","axes[2].set_title('Sagittal MIP (Side View)', fontsize=14)\n","axes[2].axis('off')\n","\n","plt.suptitle('3D Maximum Intensity Projections of Segmented Lungs', fontsize=16)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Y0DhpZGz9cu6"},"source":["### Segmentation Metrics\n","\n","Let's calculate some quantitative metrics about the segmentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ScbOMMd29cu6"},"outputs":[],"source":["# Calculate lung volume\n","voxel_volume = np.prod(ct_image.metadata.get('spacing', [1, 1, 1])) / 1000  # Convert to mL\n","lung_volume = np.sum(lung_mask) * voxel_volume\n","\n","print(\"Lung Segmentation Metrics:\")\n","print(\"-\" * 40)\n","print(f\"Total lung volume: {lung_volume:.2f} mL\")\n","print(f\"Left lung volume: {np.sum(lung_mask[:, :, :256]) * voxel_volume:.2f} mL\")\n","print(f\"Right lung volume: {np.sum(lung_mask[:, :, 256:]) * voxel_volume:.2f} mL\")\n","\n","# Calculate mean HU in lungs\n","lung_hu_values = ct_hu.data[lung_mask]\n","print(f\"\\nMean HU in lungs: {np.mean(lung_hu_values):.2f}\")\n","print(f\"Std HU in lungs: {np.std(lung_hu_values):.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"fvG2am8A9cu6"},"source":["## 7. Spatial Standardization <a id='spatial'></a>\n","\n","Standardizing spatial properties ensures consistency across different scans."]},{"cell_type":"markdown","metadata":{"id":"qeW8OHjv9cu7"},"source":["### Resampling to Isotropic Voxels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18nUEocV9cu7"},"outputs":[],"source":["# Check current spacing\n","print(f\"Original spacing: {ct_image.metadata.get('spacing', 'Not available')}\")\n","print(f\"Original shape: {ct_image.shape}\")\n","\n","# Resample to 1mm isotropic spacing\n","resampled = processor.resample(ct_hu, spacing=(1.0, 1.0, 1.0))\n","\n","print(f\"\\nResampled spacing: {resampled.metadata.get('spacing')}\")\n","print(f\"Resampled shape: {resampled.shape}\")\n","print(f\"Size change: {resampled.shape[0] * resampled.shape[1] * resampled.shape[2] / (ct_image.shape[0] * ct_image.shape[1] * ct_image.shape[2]):.2f}x\")"]},{"cell_type":"markdown","metadata":{"id":"bLaiwH6T9cu7"},"source":["### Visualize Resampling Effect"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qU4uVFVE9cu8"},"outputs":[],"source":["# Compare original and resampled\n","fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n","\n","# Original axial\n","axes[0, 0].imshow(ct_hu.data[25], cmap='gray')\n","axes[0, 0].set_title(f\"Original Axial\\nShape: {ct_hu.data[25].shape}\")\n","axes[0, 0].axis('off')\n","\n","# Resampled axial\n","axes[0, 1].imshow(resampled.data[50], cmap='gray')\n","axes[0, 1].set_title(f\"Resampled Axial\\nShape: {resampled.data[50].shape}\")\n","axes[0, 1].axis('off')\n","\n","# Original sagittal\n","axes[1, 0].imshow(ct_hu.data[:, :, 256], cmap='gray', aspect='auto')\n","axes[1, 0].set_title(\"Original Sagittal\")\n","axes[1, 0].axis('off')\n","\n","# Resampled sagittal\n","axes[1, 1].imshow(resampled.data[:, :, 256], cmap='gray')\n","axes[1, 1].set_title(\"Resampled Sagittal (Isotropic)\")\n","axes[1, 1].axis('off')\n","\n","plt.suptitle('Effect of Isotropic Resampling', fontsize=16)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7hgOUNj_9cu8"},"source":["## 8. Intensity Normalization <a id='normalization'></a>\n","\n","Different normalization methods are suitable for different analysis tasks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3snre_TQ9cu8"},"outputs":[],"source":["# Apply different normalization methods\n","norm_methods = {\n","    \"Z-Score\": processor.normalize_intensity(ct_hu, method=\"z_score\"),\n","    \"Min-Max\": processor.normalize_intensity(ct_hu, method=\"min_max\"),\n","    \"Percentile\": processor.normalize_intensity(ct_hu, method=\"percentile\")\n","}\n","\n","# Visualize distributions\n","fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n","axes = axes.flatten()\n","\n","# Original histogram\n","axes[0].hist(ct_hu.data.flatten()[::100], bins=50, alpha=0.7, color='blue')\n","axes[0].set_title(\"Original Distribution\")\n","axes[0].set_xlabel(\"HU Value\")\n","axes[0].set_ylabel(\"Frequency\")\n","axes[0].grid(True, alpha=0.3)\n","\n","# Normalized histograms\n","for idx, (name, normalized) in enumerate(norm_methods.items(), 1):\n","    axes[idx].hist(normalized.data.flatten()[::100], bins=50, alpha=0.7, color='green')\n","    axes[idx].set_title(f\"{name} Normalization\")\n","    axes[idx].set_xlabel(\"Normalized Value\")\n","    axes[idx].set_ylabel(\"Frequency\")\n","    axes[idx].grid(True, alpha=0.3)\n","\n","    # Add statistics\n","    mean_val = np.mean(normalized.data)\n","    std_val = np.std(normalized.data)\n","    axes[idx].text(0.02, 0.98, f\"μ={mean_val:.3f}\\nσ={std_val:.3f}\",\n","                   transform=axes[idx].transAxes,\n","                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n","                   verticalalignment='top')\n","\n","plt.suptitle('Intensity Normalization Methods', fontsize=16)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"PnNonuh69cu8"},"source":["## 9. Embedding Generation <a id='embeddings'></a>\n","\n","Generate embeddings for downstream AI tasks like classification or retrieval."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_wBZ6A-9cu8"},"outputs":[],"source":["# Preprocess image for embedding generation\n","preprocessed = processor.preprocess(\n","    ct_image,\n","    denoise=True,\n","    correct_artifacts=True,\n","    resample_spacing=(2.0, 2.0, 2.0),  # Downsample for efficiency\n","    normalize=True\n",")\n","\n","print(f\"Preprocessed shape: {preprocessed.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"HXXNrIl29cu9"},"source":["### 2D vs 3D Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHUqmtNN9cu9"},"outputs":[],"source":["# Generate 2D embedding (from middle slice)\n","embedding_2d = processor.generate_embeddings(preprocessed, mode=\"2d\")\n","print(f\"2D embedding shape: {embedding_2d.shape}\")\n","\n","# Generate 3D embeddings (per-slice embeddings)\n","# Note: This will generate placeholder embeddings since REMEDIS needs proper model weights\n","print(\"\\nGenerating 3D embeddings (this may take a moment)...\")\n","embeddings_3d = processor.generate_embeddings(preprocessed, mode=\"3d\")\n","print(f\"3D embeddings shape: {embeddings_3d.shape}\")\n","\n","# Aggregate embeddings\n","agg_mean = processor.aggregate_embeddings(embeddings_3d, method=\"mean\")\n","agg_max = processor.aggregate_embeddings(embeddings_3d, method=\"max\")\n","agg_weighted = processor.aggregate_embeddings(embeddings_3d, method=\"weighted\")\n","\n","print(f\"\\nAggregated embedding shapes:\")\n","print(f\"  Mean aggregation: {agg_mean.shape}\")\n","print(f\"  Max aggregation: {agg_max.shape}\")\n","print(f\"  Weighted aggregation: {agg_weighted.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"TTxzTle49cu9"},"source":["### Visualize Embedding Space"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nlkRS7Z9cu9"},"outputs":[],"source":["# Visualize embedding values across slices\n","if len(embeddings_3d.shape) == 2 and embeddings_3d.shape[0] > 1:\n","    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n","\n","    # Mean embedding value per slice\n","    mean_per_slice = np.mean(embeddings_3d, axis=1)\n","    axes[0].plot(mean_per_slice, 'b-', linewidth=2)\n","    axes[0].set_xlabel('Slice Index')\n","    axes[0].set_ylabel('Mean Embedding Value')\n","    axes[0].set_title('Mean Embedding Value Across CT Slices')\n","    axes[0].grid(True, alpha=0.3)\n","\n","    # Embedding variance per slice\n","    var_per_slice = np.var(embeddings_3d, axis=1)\n","    axes[1].plot(var_per_slice, 'r-', linewidth=2)\n","    axes[1].set_xlabel('Slice Index')\n","    axes[1].set_ylabel('Embedding Variance')\n","    axes[1].set_title('Embedding Variance Across CT Slices')\n","    axes[1].grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Visualize embedding dimensions\n","plt.figure(figsize=(15, 6))\n","plt.imshow(embeddings_3d[:50, :100].T, aspect='auto', cmap='viridis')\n","plt.colorbar(label='Embedding Value')\n","plt.xlabel('Slice Index')\n","plt.ylabel('Embedding Dimension')\n","plt.title('Heatmap of Embedding Values (First 50 slices, 100 dimensions)')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"evRB1HCA9cu9"},"source":["## 10. Complete Pipeline Example <a id='pipeline'></a>\n","\n","Let's put it all together in a complete processing pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wxn6fGMu9cu9"},"outputs":[],"source":["def process_ct_scan(ct_path, output_dir=\"./processed_results/\"):\n","    \"\"\"\n","    Complete processing pipeline for CT scan.\n","    \"\"\"\n","    # Create output directory\n","    output_path = Path(output_dir)\n","    output_path.mkdir(exist_ok=True)\n","\n","    # Initialize processor\n","    processor = RadiologyProcessor(model=\"remedis\")\n","\n","    print(\"=\" * 50)\n","    print(\"CT SCAN PROCESSING PIPELINE\")\n","    print(\"=\" * 50)\n","\n","    # Step 1: Load DICOM\n","    print(\"\\n1. Loading DICOM series...\")\n","    ct_image = processor.load_dicom(ct_path)\n","    print(f\"   ✓ Loaded: {ct_image.shape}\")\n","\n","    # Step 2: Verify HU\n","    print(\"\\n2. Verifying Hounsfield units...\")\n","    ct_hu = processor.verify_hounsfield_units(ct_image)\n","    print(f\"   ✓ HU range: [{ct_hu.data.min():.1f}, {ct_hu.data.max():.1f}]\")\n","\n","    # Step 3: Denoise\n","    print(\"\\n3. Applying denoising...\")\n","    denoised = processor.denoise(ct_hu, method=\"nlm\")\n","    print(\"   ✓ Non-local means denoising applied\")\n","\n","    # Step 4: Segment lungs\n","    print(\"\\n4. Segmenting lungs...\")\n","    try:\n","        lung_mask = processor.segment_lungs(denoised)\n","        lung_volume = np.sum(lung_mask) * np.prod(ct_image.metadata.get('spacing', [1, 1, 1])) / 1000\n","        print(f\"   ✓ Lung volume: {lung_volume:.2f} mL\")\n","\n","        # Save lung mask\n","        np.save(output_path / \"lung_mask.npy\", lung_mask)\n","    except Exception as e:\n","        print(f\"   ⚠ Lung segmentation failed: {e}\")\n","        lung_mask = None\n","\n","    # Step 5: Normalize\n","    print(\"\\n5. Normalizing intensities...\")\n","    normalized = processor.normalize_intensity(denoised, method=\"percentile\")\n","    print(\"   ✓ Percentile normalization applied\")\n","\n","    # Step 6: Resample\n","    print(\"\\n6. Resampling to isotropic spacing...\")\n","    resampled = processor.resample(normalized, spacing=(1.5, 1.5, 1.5))\n","    print(f\"   ✓ Resampled to: {resampled.shape}\")\n","\n","    # Step 7: Generate embeddings\n","    print(\"\\n7. Generating embeddings...\")\n","    embeddings = processor.generate_embeddings(resampled, mode=\"2d\")\n","    print(f\"   ✓ Embedding shape: {embeddings.shape}\")\n","\n","    # Save embeddings\n","    np.save(output_path / \"embeddings.npy\", embeddings)\n","\n","    # Create summary visualization\n","    print(\"\\n8. Creating summary visualization...\")\n","    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n","    axes = axes.flatten()\n","\n","    slice_idx = min(25, ct_image.shape[0] // 2)\n","\n","    # Original\n","    axes[0].imshow(ct_image.data[slice_idx], cmap='gray')\n","    axes[0].set_title(\"Original CT\")\n","    axes[0].axis('off')\n","\n","    # HU corrected\n","    axes[1].imshow(ct_hu.data[slice_idx], cmap='gray')\n","    axes[1].set_title(\"HU Corrected\")\n","    axes[1].axis('off')\n","\n","    # Denoised\n","    axes[2].imshow(denoised.data[slice_idx], cmap='gray')\n","    axes[2].set_title(\"Denoised\")\n","    axes[2].axis('off')\n","\n","    # Lung mask\n","    if lung_mask is not None:\n","        axes[3].imshow(lung_mask[slice_idx], cmap='hot')\n","        axes[3].set_title(\"Lung Mask\")\n","    else:\n","        axes[3].text(0.5, 0.5, \"N/A\", ha='center', va='center', fontsize=20)\n","        axes[3].set_title(\"Lung Mask (Failed)\")\n","    axes[3].axis('off')\n","\n","    # Normalized\n","    axes[4].imshow(normalized.data[slice_idx], cmap='gray')\n","    axes[4].set_title(\"Normalized\")\n","    axes[4].axis('off')\n","\n","    # Final preprocessed\n","    final_slice_idx = min(slice_idx * 2, resampled.shape[0] - 1)\n","    axes[5].imshow(resampled.data[final_slice_idx], cmap='gray')\n","    axes[5].set_title(\"Final Preprocessed\")\n","    axes[5].axis('off')\n","\n","    plt.suptitle('CT Processing Pipeline Summary', fontsize=18)\n","    plt.tight_layout()\n","    plt.savefig(output_path / \"pipeline_summary.png\", dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","    print(\"\\n\" + \"=\" * 50)\n","    print(\"PROCESSING COMPLETE\")\n","    print(f\"Results saved to: {output_path.absolute()}\")\n","    print(\"=\" * 50)\n","\n","    return {\n","        'embeddings': embeddings,\n","        'lung_mask': lung_mask,\n","        'processed_image': resampled\n","    }\n","\n","# Run the complete pipeline\n","results = process_ct_scan(ct_dir)"]},{"cell_type":"markdown","metadata":{"id":"k50eyYiY9cu-"},"source":["## 11. Advanced Topics <a id='advanced'></a>\n","\n","### Metal Artifact Reduction\n","\n","For CT scans with metal implants:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7e5vA7S9cu-"},"outputs":[],"source":["# Detect and reduce metal artifacts\n","# Check if there are high HU values indicating metal\n","metal_threshold = 3000\n","has_metal = np.any(ct_hu.data > metal_threshold)\n","\n","if has_metal:\n","    print(\"Metal artifacts detected! Applying reduction...\")\n","    reduced = processor.reduce_metal_artifacts(ct_hu)\n","\n","    # Visualize the effect\n","    slice_with_metal = np.argmax(np.max(ct_hu.data, axis=(1, 2)) > metal_threshold)\n","\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n","    axes[0].imshow(ct_hu.data[slice_with_metal], cmap='gray')\n","    axes[0].set_title(\"Original with Metal Artifacts\")\n","    axes[0].axis('off')\n","\n","    axes[1].imshow(reduced.data[slice_with_metal], cmap='gray')\n","    axes[1].set_title(\"After Metal Artifact Reduction\")\n","    axes[1].axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No significant metal artifacts detected in this scan.\")"]},{"cell_type":"markdown","metadata":{"id":"R9K-DP2Z9cu-"},"source":["### Multi-Modality Processing\n","\n","HoneyBee can handle different imaging modalities with appropriate preprocessing:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDroKEmB9cu-"},"outputs":[],"source":["# Example: Processing parameters for different modalities\n","modality_configs = {\n","    \"CT\": {\n","        \"denoise_method\": \"nlm\",\n","        \"normalize_method\": \"percentile\",\n","        \"window_presets\": [\"lung\", \"soft_tissue\", \"bone\"]\n","    },\n","    \"MRI\": {\n","        \"denoise_method\": \"rician\",  # MRI-specific noise model\n","        \"normalize_method\": \"z_score\",\n","        \"bias_correction\": True\n","    },\n","    \"PET\": {\n","        \"denoise_method\": \"pet_specific\",\n","        \"normalize_method\": \"min_max\",\n","        \"calculate_suv\": True\n","    }\n","}\n","\n","# Display modality-specific processing\n","for modality, config in modality_configs.items():\n","    print(f\"\\n{modality} Processing Configuration:\")\n","    print(\"-\" * 40)\n","    for key, value in config.items():\n","        print(f\"  {key}: {value}\")"]},{"cell_type":"markdown","metadata":{"id":"TruItnQI9cu-"},"source":["### Performance Optimization Tips\n","\n","When processing large datasets:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7I2qejp9cu-"},"outputs":[],"source":["# Memory-efficient processing example\n","def process_large_dataset(dicom_paths, batch_size=10):\n","    \"\"\"\n","    Process multiple CT scans efficiently.\n","    \"\"\"\n","    processor = RadiologyProcessor(model=\"remedis\")\n","    all_embeddings = []\n","\n","    for i in range(0, len(dicom_paths), batch_size):\n","        batch_paths = dicom_paths[i:i+batch_size]\n","\n","        for path in batch_paths:\n","            # Process with lower resolution for speed\n","            ct = processor.load_dicom(path)\n","\n","            # Quick preprocessing\n","            preprocessed = processor.preprocess(\n","                ct,\n","                denoise=False,  # Skip for speed\n","                resample_spacing=(3.0, 3.0, 3.0),  # Lower resolution\n","                normalize=True\n","            )\n","\n","            # Generate embeddings\n","            embedding = processor.generate_embeddings(preprocessed, mode=\"2d\")\n","            all_embeddings.append(embedding)\n","\n","            # Clear memory\n","            del ct, preprocessed\n","\n","        print(f\"Processed batch {i//batch_size + 1}\")\n","\n","    return np.vstack(all_embeddings)\n","\n","print(\"Example batch processing function defined.\")\n","print(\"\\nOptimization tips:\")\n","print(\"- Use lower resolution for initial screening\")\n","print(\"- Process in batches to manage memory\")\n","print(\"- Skip non-essential preprocessing steps\")\n","print(\"- Use GPU acceleration when available\")\n","print(\"- Cache intermediate results\")"]},{"cell_type":"markdown","metadata":{"id":"kkrJTCPL9cu-"},"source":["## Summary\n","\n","In this tutorial, we've covered:\n","\n","1. **Loading medical images** from DICOM format\n","2. **Preprocessing techniques** including HU correction and denoising\n","3. **Window/level adjustment** for optimal visualization\n","4. **Anatomical segmentation** with focus on lung extraction\n","5. **Spatial standardization** through resampling\n","6. **Intensity normalization** methods\n","7. **Embedding generation** for AI applications\n","8. **Complete processing pipeline** implementation\n","\n","### Next Steps\n","\n","- Experiment with different preprocessing parameters\n","- Try processing different types of medical images (MRI, PET)\n","- Integrate the embeddings with downstream ML models\n","- Explore multi-modal fusion with HoneyBee's integration capabilities\n","\n","### Resources\n","\n","- [HoneyBee Documentation](https://lab-rasool.github.io/HoneyBee/docs/)\n","- [Medical Image Processing Best Practices](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3372692/)\n","- [DICOM Standard](https://www.dicomstandard.org/)"]}],"metadata":{"kernelspec":{"display_name":"HoneyBee","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}